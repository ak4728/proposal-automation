{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdullah.kurkcu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import json\n",
    "from re import findall\n",
    "from re import sub\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PyPDF2\n",
    "import glob\n",
    "import en_core_web_sm\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import re  \n",
    "import nltk  \n",
    "from sklearn.datasets import load_files \n",
    "nltk.download('stopwords')  \n",
    "import pickle  \n",
    "from nltk.corpus import stopwords\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fontgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def fonts(doc, granularity=False):\n",
    "    \"\"\"Extracts fonts and their usage in PDF documents.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param granularity: also use 'font', 'flags' and 'color' to discriminate text\n",
    "    :type granularity: bool\n",
    "    :rtype: [(font_size, count), (font_size, count}], dict\n",
    "    :return: most used fonts sorted by count, font style information\n",
    "    \"\"\"\n",
    "    styles = {}\n",
    "    font_counts = {}\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if granularity:\n",
    "                            styles[s['font']] =  {'size':s['size'],'color':s['color']}\n",
    "                        else:\n",
    "                            styles[s['font']] =  {'size':s['size'],'color':s['color']}\n",
    "\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../resumesnot\\19.00150_Town of Vail_Gore Valley Trail_Feb19_FINAL_LR.pdf\n",
      "'PageObject' object has no attribute 'getText'\n",
      "../resumesnot\\19.00150_Town of Vail_Gore Valley Trail_Feb19_FINAL_LR_Part1.pdf\n",
      "'PageObject' object has no attribute 'getText'\n",
      "../resumesnot\\21.00876 Becker County Heartland Trail Engineering & Design Services - Final.pdf\n",
      "'PageObject' object has no attribute 'getText'\n",
      "../resumesnot\\21.00980 Sioux City Proposal.pdf\n",
      "'PageObject' object has no attribute 'getText'\n"
     ]
    }
   ],
   "source": [
    "# All the pdf files in the folder\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % \"../resumesnot/\")\n",
    "\n",
    "\n",
    "# Resumes -> convert to a dictionary with an employee name\n",
    "resumesTest = pd.DataFrame()\n",
    "\n",
    "text_dict = {}\n",
    "# File loop\n",
    "for file in pdf_files:\n",
    "    print(file)\n",
    "    text = \"\"\n",
    "    try:\n",
    "        fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "        count = fileReader.numPages\n",
    "        text = \"\"\n",
    "        i = 0\n",
    "        while i < count:\n",
    "            text = fileReader.getPage(i).extractText()\n",
    "            print(fileReader.getPage(i).getText())\n",
    "            i = i +1  \n",
    "            # lowercase\n",
    "            text = text.lower()\n",
    "            # remove nubmers\n",
    "            text = re.sub(r'\\d+', '', text)\n",
    "            # remove punctuation\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "            # remove \\n\n",
    "            text = text.replace('\\n',' ')\n",
    "            # remove ndł\n",
    "            text= text.replace('ndł',' ')\n",
    "            # remove \\nł\n",
    "            text = text.replace('\\nł',' ')\n",
    "            # remove ł\n",
    "            text = text.replace('ł',' ')\n",
    "            # remove \\nł\n",
    "            text = text.replace('\\nł',' ')\n",
    "            if len(text) > 200:\n",
    "                ,list(fonts(doc).values())\n",
    "\n",
    "                text_dict[i] = {'text':text,\n",
    "                                'fonts':list(fonts(doc).keys()), \n",
    "                                'size': [x['size'] for x in list(fonts(doc).values())],\n",
    "                                'color':[x['color'] for x in list(fonts(doc).values())]\n",
    "                               }\n",
    "            else:\n",
    "                pass\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NewsGothicStd-Bold': {'size': 10.0, 'color': 2236191, 'text': 'Training'},\n",
       " 'NewsGothicStd': {'size': 10.0,\n",
       "  'color': 2236191,\n",
       "  'text': 'Applied Roadway Design'}}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open(\"../resumes/17.00532 2.pdf\")\n",
    "\n",
    "styles = {}\n",
    "\n",
    "for page in doc:\n",
    "    blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "    for b in blocks:  # iterate through the text blocks\n",
    "        if b['type'] == 0:  # block contains text\n",
    "            for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        styles[s['font']] =  {'size':s['size'],'color':s['color'],'text':s['text']}\n",
    "styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['NewsGothicStd-Bold', 'NewsGothicStd'],\n",
       " [{'size': 10.0, 'color': 2236191}, {'size': 10.0, 'color': 2236191}])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "doc = fitz.open(\"../resumes/17.00532 2.pdf\")\n",
    "list(fonts(doc).keys()),list(fonts(doc).values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 10.0]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x['size'] for x in list(fonts(doc).values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def fonts(doc, granularity=False):\n",
    "    \"\"\"Extracts fonts and their usage in PDF documents.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param granularity: also use 'font', 'flags' and 'color' to discriminate text\n",
    "    :type granularity: bool\n",
    "    :rtype: [(font_size, count), (font_size, count}], dict\n",
    "    :return: most used fonts sorted by count, font style information\n",
    "    \"\"\"\n",
    "    styles = {}\n",
    "    font_counts = {}\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if granularity:\n",
    "                            styles[s['font']] =  {'size':s['size'],'color':s['color']}\n",
    "                        else:\n",
    "                            styles[s['font']] =  {'size':s['size'],'color':s['color']}\n",
    "\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../resumes\\17.00532 0.pdf\n",
      "../resumes\\17.00532 1.pdf\n",
      "../resumes\\17.00532 2.pdf\n",
      "../resumes\\17.00532 3.pdf\n",
      "../resumes\\18.00308 0.pdf\n",
      "../resumes\\18.00308 1.pdf\n",
      "../resumes\\18.00308 2.pdf\n",
      "../resumes\\18.00308 3.pdf\n",
      "../resumes\\19.00064 0.pdf\n",
      "../resumes\\19.00064 1.pdf\n",
      "../resumes\\19.00064 10.pdf\n",
      "../resumes\\19.00064 11.pdf\n",
      "../resumes\\19.00064 2.pdf\n",
      "../resumes\\19.00064 3.pdf\n",
      "../resumes\\19.00064 4.pdf\n",
      "../resumes\\19.00064 5.pdf\n",
      "../resumes\\19.00064 6.pdf\n",
      "../resumes\\19.00064 7.pdf\n",
      "../resumes\\19.00064 8.pdf\n",
      "../resumes\\19.00064 9.pdf\n",
      "../resumes\\20.00432 0.pdf\n",
      "../resumes\\20.00432 1.pdf\n",
      "../resumes\\20.00432 2.pdf\n",
      "../resumes\\20.00432 3.pdf\n",
      "../resumes\\20.00432 4.pdf\n",
      "../resumes\\20.00973 0.pdf\n",
      "../resumes\\20.00973 1.pdf\n",
      "../resumes\\20.00973 10.pdf\n",
      "../resumes\\20.00973 11.pdf\n",
      "../resumes\\20.00973 12.pdf\n",
      "../resumes\\20.00973 2.pdf\n",
      "../resumes\\20.00973 3.pdf\n",
      "../resumes\\20.00973 4.pdf\n",
      "../resumes\\20.00973 5.pdf\n",
      "../resumes\\20.00973 6.pdf\n",
      "../resumes\\20.00973 7.pdf\n",
      "../resumes\\20.00973 8.pdf\n",
      "../resumes\\20.00973 9.pdf\n",
      "../resumes\\20.01139 0.pdf\n",
      "../resumes\\20.01139 1.pdf\n",
      "../resumes\\20.01139 2.pdf\n",
      "../resumes\\20.01139 3.pdf\n",
      "../resumes\\20.01139 4.pdf\n",
      "../resumes\\20.01139 5.pdf\n",
      "../resumes\\20.01139 6.pdf\n",
      "../resumes\\20.01139 7.pdf\n",
      "../resumes\\20.02068 0.pdf\n",
      "../resumes\\20.02068 1.pdf\n",
      "../resumes\\20.02068 2.pdf\n",
      "../resumes\\20.02068 3.pdf\n",
      "../resumes\\20.02068 4.pdf\n",
      "../resumes\\20.02068 5.pdf\n",
      "../resumes\\20.02068 6.pdf\n",
      "../resumes\\20.02068 7.pdf\n",
      "../resumes\\20.02564 0.pdf\n",
      "../resumes\\20.02564 1.pdf\n",
      "../resumes\\20.02564 10.pdf\n",
      "../resumes\\20.02564 11.pdf\n",
      "../resumes\\20.02564 12.pdf\n",
      "../resumes\\20.02564 2.pdf\n",
      "../resumes\\20.02564 3.pdf\n",
      "../resumes\\20.02564 4.pdf\n",
      "../resumes\\20.02564 5.pdf\n",
      "../resumes\\20.02564 6.pdf\n",
      "../resumes\\20.02564 7.pdf\n",
      "../resumes\\20.02564 8.pdf\n",
      "../resumes\\20.02564 9.pdf\n",
      "../resumes\\21.00599 0.pdf\n",
      "../resumes\\21.00599 1.pdf\n",
      "../resumes\\21.00599 10.pdf\n",
      "../resumes\\21.00599 11.pdf\n",
      "../resumes\\21.00599 12.pdf\n",
      "../resumes\\21.00599 13.pdf\n",
      "../resumes\\21.00599 2.pdf\n",
      "../resumes\\21.00599 3.pdf\n",
      "../resumes\\21.00599 4.pdf\n",
      "../resumes\\21.00599 5.pdf\n",
      "../resumes\\21.00599 6.pdf\n",
      "../resumes\\21.00599 7.pdf\n",
      "../resumes\\21.00599 8.pdf\n",
      "../resumes\\21.00599 9.pdf\n",
      "../resumes\\not (1).pdf\n",
      "../resumes\\not (10).pdf\n",
      "../resumes\\not (11).pdf\n",
      "../resumes\\not (12).pdf\n",
      "../resumes\\not (13).pdf\n",
      "../resumes\\not (14).pdf\n",
      "../resumes\\not (15).pdf\n",
      "../resumes\\not (16).pdf\n",
      "../resumes\\not (17).pdf\n",
      "../resumes\\not (18).pdf\n",
      "../resumes\\not (19).pdf\n",
      "../resumes\\not (2).pdf\n",
      "../resumes\\not (20).pdf\n",
      "../resumes\\not (21).pdf\n",
      "../resumes\\not (22).pdf\n",
      "../resumes\\not (23).pdf\n",
      "../resumes\\not (24).pdf\n",
      "../resumes\\not (25).pdf\n",
      "../resumes\\not (26).pdf\n",
      "../resumes\\not (27).pdf\n",
      "../resumes\\not (28).pdf\n",
      "../resumes\\not (29).pdf\n",
      "../resumes\\not (3).pdf\n",
      "../resumes\\not (30).pdf\n",
      "../resumes\\not (31).pdf\n",
      "../resumes\\not (32).pdf\n",
      "../resumes\\not (33).pdf\n",
      "../resumes\\not (34).pdf\n",
      "../resumes\\not (35).pdf\n",
      "../resumes\\not (36).pdf\n",
      "../resumes\\not (4).pdf\n",
      "../resumes\\not (5).pdf\n",
      "../resumes\\not (6).pdf\n",
      "../resumes\\not (7).pdf\n",
      "../resumes\\not (8).pdf\n",
      "../resumes\\not (9).pdf\n"
     ]
    }
   ],
   "source": [
    "# All the pdf files in the folder\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % \"../resumes/\")\n",
    "\n",
    "\n",
    "# Resumes -> convert to a dictionary with an employee name\n",
    "resumes = pd.DataFrame()\n",
    "\n",
    "texts = []\n",
    "# File loop\n",
    "for file in pdf_files:\n",
    "    print(file)\n",
    "    text = \"\"\n",
    "    try:\n",
    "        fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "        count = fileReader.numPages\n",
    "        text = \"\"\n",
    "        i = 0\n",
    "        while i < count:\n",
    "            text += fileReader.getPage(i).extractText()\n",
    "            i = i +1  \n",
    "        # lowercase\n",
    "        text = text.lower()\n",
    "        # remove nubmers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        # remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # remove \\n\n",
    "        text = text.replace('\\n',' ')\n",
    "        # remove ndł\n",
    "        text= text.replace('ndł',' ')\n",
    "        # remove \\nł\n",
    "        text = text.replace('\\nł',' ')\n",
    "        # remove ł\n",
    "        text = text.replace('ł',' ')\n",
    "        # remove \\nł\n",
    "        text = text.replace('\\nł',' ')\n",
    "\n",
    "        texts.append(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "resumes['text'] = texts\n",
    "resumes['classification'] = \"Resume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resumes.loc[81:117, 'classification']  = 'NotResume'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angy casamento peproject manager angy is a lea...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mike dora peprincipalincharge mike is the mark...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andria schmid peqaqcandria works with the civi...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andria schmid peqaqcandria works with the civi...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angy casamento peproject manager angy is a lea...</td>\n",
       "      <td>Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>project approach</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>project approachproject understanding the proj...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>project approachthe project both in terms of t...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>this page is intentionally left blank</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>firm  experience</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text classification\n",
       "0    angy casamento peproject manager angy is a lea...         Resume\n",
       "1    mike dora peprincipalincharge mike is the mark...         Resume\n",
       "2    andria schmid peqaqcandria works with the civi...         Resume\n",
       "3    andria schmid peqaqcandria works with the civi...         Resume\n",
       "4    angy casamento peproject manager angy is a lea...         Resume\n",
       "..                                                 ...            ...\n",
       "112                                  project approach       NotResume\n",
       "113  project approachproject understanding the proj...      NotResume\n",
       "114  project approachthe project both in terms of t...      NotResume\n",
       "115              this page is intentionally left blank      NotResume\n",
       "116                                   firm  experience      NotResume\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert text into a vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "\n",
    "# Do not call fit transform twice because it is stored in vectorizer \n",
    "X_train = vectorizer.fit_transform(resumes['text'])\n",
    "X_test = vectorizer.transform(resumesTest['text'])\n",
    "y_train = resumes['classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)  \n",
    "text_clf  = classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'Resume', 'Resume', 'Resume', 'Resume',\n",
       "       'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume',\n",
       "       'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume',\n",
       "       'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../downloaded/20.02373 CDOT NPS Western Slope_Ulteig.pdf'\n",
    "fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "count = fileReader.numPages\n",
    "\n",
    "\n",
    "results = text_clf.predict(X_test)\n",
    "resumesTest['results'] = results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' downtown infrastructure reconstruction master plan  city of sioux city  iowa      may       quality  control and  quality  assurance  quality control   in his role as project manager charlie bechtold pe  will be responsible for coordinating activities to provide effective workflow and  meet the deliverable milestones during  each  phase of this project  maintain project schedule   project milestones and tasks will follow a schedule made by  the  ulteig  team  and agreeable to the city of sioux city the team will  develop a detailed project schedule using microsoft project software the project schedule incorporates critical path activi ties for  components of the project and identifies milestone dates for project deliverables ulteig™s  project  panagement staff will also provide  detailed biweekly reports to the assigned individuals  request ing  the reports  maintain central project fil e ulteig will establish a central project file  to become  the repository for all critical  project  documents  this includes calculation sheets  planning documents project  checklists  communication records project cost estimates  progress reports drawing files  models  and final plan documents all project staff will be responsible for maintaining records of all written verbal and electroni c correspondence and will save these records in the central project file project communication including meeting minutes  telep hone conversations internal project meetings and formal communication will be documented we will distribute records of  communication of all critical discussion items to  meeting participants  in addition to these project level processes each  key component  will have additional quality control measures in general  this  involves  checking all calculations and inputs and reviewing all draft and final products for accuracy all design calculations will be  checked by an equally or mo re experienced staff member with similar experience  quality assurance  the qa for this project will be completed by  chad stensland  pe  he possesses a solid technical design background and  understands city of sioux city project development processes and pr otocol he will continually monitor the qc procedures as  outlined in the proposal and make sure that each team member follows the same procedures checking will be performed by  qualified individuals not directly involved with design or the planning documen t he will also review documents prior to submittal to  the client as he will typically not be involved with the day today preparation of the planning or design documents  electronic process   the  ulteig  team  has developed an action plan for the qcqa proc ess that uses available software to review documents  electronically within a shared environment the software tracks multiple reviewers making corrections to a file in real time  the  system logs the time of the comment and the person who made it no review er can delete or change a comment made by another  reviewer changes in status or additional notes made to an existing comment are also logged with time stamp and reviewer™s  name at any time during the review process the log can be exported and made avail able to the client  the originator uploads the file to the software and sends invitations out to reviewers each reviewer will pick a different c olor for his  or her comments color coding comments is not necessary since the system logs the identity of the  comment author automatically  but the color coding does make it easier to identify the author at a glance after the comment period has ended the originator will  review all comments and approve or reject them once all review comments have been approved or  rejected the originator will  then download the file log and save it to the project for records   the plans will then be corrected as directed in the reviewed file as each item is addressed the review comment is marked  ﬁcompletedﬂ within the software  as with the creation of the comments all status changes and notes to the completed items have  the name and time stamp of the change recorded in the log after all comments have been corrected and all items have been  marked completed the file and log wil l again be downloaded and a copy saved to the project for records when the process is  complete there should be at least five documents created which will provide adequate documentation that the reports have go ne  through the qcqa process documents will  include the original file the file with all review comments and the log and the  completed file and log  '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumesTest['text'][48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proposal to perform professional engineering services for  gore valley trail design improvements prepared for town of vail angy casamento peangycasamentoulteigcom       february  '"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumesTest['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "i = 0\n",
    "X_test = []\n",
    "while i < count:\n",
    "    text = fileReader.getPage(i).extractText()\n",
    "    X_test.append(text)\n",
    "    \n",
    "    i = i +1  \n",
    "\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proposal to perform professional engineering services for  gore valley trail design improvements prepared for town of vail angy casamento peangycasamentoulteigcom       february  '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumesTest.loc[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proposal to perform professional engineering s...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proposal to perform professional engineering s...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>proposal to perform professional engineering s...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proposal to perform professional engineering s...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proposal to perform professional engineering s...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ulteig  sioux city  office   th street suite ...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ulteig  sioux city  office   th street suite ...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ulteig  sioux city  office   th street suite ...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ulteig  sioux city  office   th street suite ...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ulteig  sioux city  office   th street suite ...</td>\n",
       "      <td>NotResume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text classification\n",
       "0   proposal to perform professional engineering s...      NotResume\n",
       "1   proposal to perform professional engineering s...      NotResume\n",
       "2   proposal to perform professional engineering s...      NotResume\n",
       "3   proposal to perform professional engineering s...      NotResume\n",
       "4   proposal to perform professional engineering s...      NotResume\n",
       "..                                                ...            ...\n",
       "56   ulteig  sioux city  office   th street suite ...      NotResume\n",
       "57   ulteig  sioux city  office   th street suite ...      NotResume\n",
       "58   ulteig  sioux city  office   th street suite ...      NotResume\n",
       "59   ulteig  sioux city  office   th street suite ...      NotResume\n",
       "60   ulteig  sioux city  office   th street suite ...      NotResume\n",
       "\n",
       "[61 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumesTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "PDFInfoNotInstalledError",
     "evalue": "Unable to get page count. Is poppler installed and in PATH?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdf2image\\pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[0;32m    444\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LD_LIBRARY_PATH\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoppler_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LD_LIBRARY_PATH\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-005dcd6eff1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../downloaded/20.02373 CDOT NPS Western Slope_Ulteig.pdf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdf2image\\pdf2image.py\u001b[0m in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mpoppler_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mpage_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdfinfo_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserpw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpoppler_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pages\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;31m# We start by getting the output format, the buffer processing function and if we need pdftocairo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdf2image\\pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         raise PDFInfoNotInstalledError(\n\u001b[1;32m--> 472\u001b[1;33m             \u001b[1;34m\"Unable to get page count. Is poppler installed and in PATH?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m         )\n\u001b[0;32m    474\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m: Unable to get page count. Is poppler installed and in PATH?"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "file = '../downloaded/20.02373 CDOT NPS Western Slope_Ulteig.pdf'\n",
    "images = convert_from_path(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
