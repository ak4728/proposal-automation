{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import json\n",
    "from re import findall\n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available. [ipykernel_launcher.py:36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________ \n",
      " 87%  Similarity \n",
      " ../downloaded\\18.00308 Jefferson County_RoadwaySignage_Mar13_P18.00308_FINAL.pdf \n",
      " ____________________________________________________________________________________________________\n",
      "Unsupported PNG filter 3\n",
      "____________________________________________________________________________________________________ \n",
      " 93%  Similarity \n",
      " ../downloaded\\19.00150_Town of Vail_Gore Valley Trail_Feb19_FINAL_LR.pdf \n",
      " ____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PyPDF2\n",
    "import glob\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# Downtown Infrastructure Reconstruction RFQ.pdf\n",
    "\n",
    "fileReader = PyPDF2.PdfFileReader(open(\"../downloaded/SOW.pdf\",'rb'))\n",
    "\n",
    "count = fileReader.numPages\n",
    "i = 0\n",
    "text = \"\"\n",
    "while i < count:\n",
    "    text += fileReader.getPage(i).extractText()\n",
    "    i = i +1\n",
    "doc1 = nlp(text)\n",
    "EOF_MARKER = b'%%EOF'\n",
    "\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % \"../downloaded/\")\n",
    "\n",
    "for file in pdf_files[1:4]:\n",
    "    try:\n",
    "        fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "        count = fileReader.numPages\n",
    "        \n",
    "        text = \"\"\n",
    "        i = 0\n",
    "        while i < count:\n",
    "            text += fileReader.getPage(i).extractText()\n",
    "            i = i +1  \n",
    "        doc2 = nlp(text)\n",
    "        sim_score = doc1.similarity(doc2)\n",
    "        if float(sim_score) > 0.85:\n",
    "            print(\"_\" * 100,\"\\n\",\"{:.0%}\".format(sim_score), \" Similarity \\n\", \"{}\".format(file),\"\\n\",\"_\" * 100,)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
