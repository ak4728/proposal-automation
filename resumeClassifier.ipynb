{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdullah.kurkcu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import json\n",
    "from re import findall\n",
    "from re import sub\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PyPDF2\n",
    "import glob\n",
    "import en_core_web_sm\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import re  \n",
    "import nltk  \n",
    "from sklearn.datasets import load_files \n",
    "nltk.download('stopwords')  \n",
    "import pickle  \n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Resumes into DataFrame\n",
    "\n",
    "Does it have education?\n",
    "Does it have professional?\n",
    "Does it have project experience?\n",
    "Does it have professional associations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n",
      "mupdf: invalid page object\n"
     ]
    }
   ],
   "source": [
    "# All the pdf files in the folder\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % \"../resumes/\")\n",
    "\n",
    "i = 0 # 81 is the start of not resume\n",
    "styles = {}\n",
    "for file in pdf_files:\n",
    "    doc = fitz.open(file)\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        fonts = []\n",
    "        sizes = []\n",
    "        colors = []\n",
    "        images = []\n",
    "        body = ''\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        body += \" \" + s['text'].lower()\n",
    "                        fonts.append(s['font'])\n",
    "                        sizes.append(s['size'])\n",
    "                        colors.append(s['color'])\n",
    "            if b['type'] == 1:  # block contains image\n",
    "                images.append(1)\n",
    "        if 'education' in body:\n",
    "            ed_check = 1\n",
    "        else:\n",
    "            ed_check = 0\n",
    "        if 'professional registrations' in body:\n",
    "            pr_check = 1\n",
    "        else:\n",
    "            pr_check = 0\n",
    "        if 'associations' in body:\n",
    "            pa_check = 1\n",
    "        else:\n",
    "            pa_check = 0\n",
    "        if 'experience' in body:\n",
    "            pe_check = 1\n",
    "        else:\n",
    "            pe_check = 0\n",
    "        if len(images)>0:\n",
    "            img_check = 1\n",
    "        else:\n",
    "            img_check = 0\n",
    "        \n",
    "    if i < 81:\n",
    "        label = 'resume'\n",
    "    else:\n",
    "        label = 'not resume'\n",
    "    styles[doc] =  {'name':doc, 'body':body,'fonts':list(set(fonts)), 'size':list(set(sizes)),'color':list(set(colors)),'education':ed_check, 'registrations':pr_check,\n",
    "                   'associations':pa_check, 'experience':pe_check, 'image':img_check, 'label':label}\n",
    "    i = i + 1\n",
    "\n",
    "data = pd.DataFrame.from_dict(styles, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>body</th>\n",
       "      <th>fonts</th>\n",
       "      <th>size</th>\n",
       "      <th>color</th>\n",
       "      <th>education</th>\n",
       "      <th>registrations</th>\n",
       "      <th>associations</th>\n",
       "      <th>experience</th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(page 0 of ../resumes\\17.00532 0.pdf)</th>\n",
       "      <td>(page 0 of ../resumes\\17.00532 0.pdf)</td>\n",
       "      <td>15 buena vista  /  midland hills bridge trail...</td>\n",
       "      <td>[NewsGothicStd, NewsGothicStd-Bold]</td>\n",
       "      <td>[8.0, 10.0, 12.0, 14.0]</td>\n",
       "      <td>[16777215, 32117, 2236191]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(page 0 of ../resumes\\17.00532 1.pdf)</th>\n",
       "      <td>(page 0 of ../resumes\\17.00532 1.pdf)</td>\n",
       "      <td>16 buena vista  /  midland hills bridge trail...</td>\n",
       "      <td>[NewsGothicStd, NewsGothicStd-Bold]</td>\n",
       "      <td>[8.0, 10.0, 12.0, 14.0]</td>\n",
       "      <td>[32117, 2236191]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(page 0 of ../resumes\\17.00532 2.pdf)</th>\n",
       "      <td>(page 0 of ../resumes\\17.00532 2.pdf)</td>\n",
       "      <td>17 buena vista  /  midland hills bridge trail...</td>\n",
       "      <td>[NewsGothicStd, NewsGothicStd-Bold]</td>\n",
       "      <td>[8.0, 10.0, 12.0, 14.0]</td>\n",
       "      <td>[32117, 2236191]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(page 0 of ../resumes\\17.00532 3.pdf)</th>\n",
       "      <td>(page 0 of ../resumes\\17.00532 3.pdf)</td>\n",
       "      <td>17 buena vista  /  midland hills bridge trail...</td>\n",
       "      <td>[NewsGothicStd, NewsGothicStd-Bold]</td>\n",
       "      <td>[8.0, 10.0, 12.0, 14.0]</td>\n",
       "      <td>[32117, 2236191]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(page 0 of ../resumes\\18.00308 0.pdf)</th>\n",
       "      <td>(page 0 of ../resumes\\18.00308 0.pdf)</td>\n",
       "      <td>14 jefferson county open space  /  roadway si...</td>\n",
       "      <td>[NewsGothicStd, NewsGothicStd-Bold]</td>\n",
       "      <td>[8.0, 10.0, 12.0, 14.0]</td>\n",
       "      <td>[32117, 2236191]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        name  \\\n",
       "(page 0 of ../resumes\\17.00532 0.pdf)  (page 0 of ../resumes\\17.00532 0.pdf)   \n",
       "(page 0 of ../resumes\\17.00532 1.pdf)  (page 0 of ../resumes\\17.00532 1.pdf)   \n",
       "(page 0 of ../resumes\\17.00532 2.pdf)  (page 0 of ../resumes\\17.00532 2.pdf)   \n",
       "(page 0 of ../resumes\\17.00532 3.pdf)  (page 0 of ../resumes\\17.00532 3.pdf)   \n",
       "(page 0 of ../resumes\\18.00308 0.pdf)  (page 0 of ../resumes\\18.00308 0.pdf)   \n",
       "\n",
       "                                                                                    body  \\\n",
       "(page 0 of ../resumes\\17.00532 0.pdf)   15 buena vista  /  midland hills bridge trail...   \n",
       "(page 0 of ../resumes\\17.00532 1.pdf)   16 buena vista  /  midland hills bridge trail...   \n",
       "(page 0 of ../resumes\\17.00532 2.pdf)   17 buena vista  /  midland hills bridge trail...   \n",
       "(page 0 of ../resumes\\17.00532 3.pdf)   17 buena vista  /  midland hills bridge trail...   \n",
       "(page 0 of ../resumes\\18.00308 0.pdf)   14 jefferson county open space  /  roadway si...   \n",
       "\n",
       "                                                                     fonts  \\\n",
       "(page 0 of ../resumes\\17.00532 0.pdf)  [NewsGothicStd, NewsGothicStd-Bold]   \n",
       "(page 0 of ../resumes\\17.00532 1.pdf)  [NewsGothicStd, NewsGothicStd-Bold]   \n",
       "(page 0 of ../resumes\\17.00532 2.pdf)  [NewsGothicStd, NewsGothicStd-Bold]   \n",
       "(page 0 of ../resumes\\17.00532 3.pdf)  [NewsGothicStd, NewsGothicStd-Bold]   \n",
       "(page 0 of ../resumes\\18.00308 0.pdf)  [NewsGothicStd, NewsGothicStd-Bold]   \n",
       "\n",
       "                                                          size  \\\n",
       "(page 0 of ../resumes\\17.00532 0.pdf)  [8.0, 10.0, 12.0, 14.0]   \n",
       "(page 0 of ../resumes\\17.00532 1.pdf)  [8.0, 10.0, 12.0, 14.0]   \n",
       "(page 0 of ../resumes\\17.00532 2.pdf)  [8.0, 10.0, 12.0, 14.0]   \n",
       "(page 0 of ../resumes\\17.00532 3.pdf)  [8.0, 10.0, 12.0, 14.0]   \n",
       "(page 0 of ../resumes\\18.00308 0.pdf)  [8.0, 10.0, 12.0, 14.0]   \n",
       "\n",
       "                                                            color  education  \\\n",
       "(page 0 of ../resumes\\17.00532 0.pdf)  [16777215, 32117, 2236191]          1   \n",
       "(page 0 of ../resumes\\17.00532 1.pdf)            [32117, 2236191]          1   \n",
       "(page 0 of ../resumes\\17.00532 2.pdf)            [32117, 2236191]          1   \n",
       "(page 0 of ../resumes\\17.00532 3.pdf)            [32117, 2236191]          1   \n",
       "(page 0 of ../resumes\\18.00308 0.pdf)            [32117, 2236191]          1   \n",
       "\n",
       "                                       registrations  associations  \\\n",
       "(page 0 of ../resumes\\17.00532 0.pdf)              1             1   \n",
       "(page 0 of ../resumes\\17.00532 1.pdf)              1             0   \n",
       "(page 0 of ../resumes\\17.00532 2.pdf)              1             0   \n",
       "(page 0 of ../resumes\\17.00532 3.pdf)              1             0   \n",
       "(page 0 of ../resumes\\18.00308 0.pdf)              1             1   \n",
       "\n",
       "                                       experience  image   label  \n",
       "(page 0 of ../resumes\\17.00532 0.pdf)           1      1  resume  \n",
       "(page 0 of ../resumes\\17.00532 1.pdf)           1      1  resume  \n",
       "(page 0 of ../resumes\\17.00532 2.pdf)           1      1  resume  \n",
       "(page 0 of ../resumes\\17.00532 3.pdf)           1      1  resume  \n",
       "(page 0 of ../resumes\\18.00308 0.pdf)           1      1  resume  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "data = data.reset_index(drop=True)\n",
    "mlb = MultiLabelBinarizer()\n",
    "df = pd.DataFrame(mlb.fit_transform(data['fonts']),columns=mlb.classes_, index=data.index)\n",
    "df2 = pd.DataFrame(mlb.fit_transform(data['size']),columns=mlb.classes_, index=data.index)\n",
    "df3 = pd.DataFrame(mlb.fit_transform(data['color']),columns=mlb.classes_, index=data.index)\n",
    "ml_data = ((df.join(df2)).join(df3)).join(data)\n",
    "ml_data = ml_data.drop(columns=['name','fonts','size','color','body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ml_data.iloc[:,-1]\n",
    "train = ml_data.iloc[:,1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "resumes_train, resumes_test, y_train, y_test = train_test_split(train, label, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arial-BoldMT', 'Arial-ItalicMT', 'ArialMT', 'ArialNarrow', 'ArialNarrow,Bold', 'ArialNarrow-Bold', 'ArialNarrow-Italic', 'AvenirLTStd-Book', 'AvenirNextLTPro-Bold', 'AvenirNextLTPro-BoldCn', 'AvenirNextLTPro-Cn', 'AvenirNextLTPro-DemiCn', 'AvenirNextLTPro-HeavyCn', 'CIDFont+F2', 'CIDFont+F3', 'CIDFont+F4', 'CIDFont+F6', 'Calibri', 'Calibri-Bold', 'Calibri-BoldItalic', 'Calibri-Italic', 'Courier', 'CourierNewPSMT', 'DINOT', 'DINOT-Bold', 'DINOT-Light', 'DINOT-LightItalic', 'Georgia', 'Georgia-Italic', 'NewsGothicStd', 'NewsGothicStd-Bold', 'NewsGothicStd-BoldObliqu', 'NewsGothicStd-Oblique', 'NoeText-Semibold', 'SegoeUI', 'Symbol', 'SymbolMT', 'TimesNewRoman', 'TimesNewRomanPSMT', 'Wingdings-Regular', 5.03507661819458, 5.039999961853027, 5.400000095367432, 6.0, 6.119999885559082, 6.473695278167725, 6.480000019073486, 6.71999979019165, 7.0, 7.019999980926514, 7.197656631469727, 7.320000171661377, 7.559999942779541, 7.7220001220703125, 7.76140022277832, 7.799200057983398, 7.803699970245361, 7.834099769592285, 7.848400115966797, 7.880000114440918, 7.88730001449585, 7.889999866485596, 7.91741418838501, 7.919996738433838, 7.980000019073486, 8.0, 8.039999961853027, 8.100000381469727, 8.520000457763672, 8.597200393676758, 8.637174606323242, 8.640999794006348, 8.669699668884277, 8.683099746704102, 8.685600280761719, 8.688199996948242, 8.717700004577637, 8.728599548339844, 8.734399795532227, 8.738100051879883, 8.76039981842041, 8.774999618530273, 8.775199890136719, 8.785900115966797, 8.813899993896484, 8.814200401306152, 8.819999694824219, 8.820899963378906, 8.831999778747559, 8.837499618530273, 8.982748985290527, 8.982749938964844, 9.0, 9.017999649047852, 9.019800186157227, 9.254599571228027, 9.279399871826172, 9.42080020904541, 9.479999542236328, 9.5, 9.515000343322754, 9.520600318908691, 9.61989974975586, 9.627400398254395, 9.647500038146973, 9.67020034790039, 9.675100326538086, 9.694899559020996, 9.711000442504883, 9.711199760437012, 9.722999572753906, 9.724300384521484, 9.7608003616333, 9.761799812316895, 9.774100303649902, 9.81309986114502, 9.881999969482422, 9.940999984741211, 9.94124984741211, 9.950390815734863, 9.960000038146973, 9.981900215148926, 10.0, 10.020000457763672, 10.07669448852539, 10.34850025177002, 10.39900016784668, 10.404999732971191, 10.445500373840332, 10.516400337219238, 10.576700210571289, 10.604999542236328, 10.718799591064453, 10.763999938964844, 10.777400016784668, 10.800000190734863, 10.819199562072754, 10.979999542236328, 11.0, 11.029430389404297, 11.039999961853027, 11.064299583435059, 11.51645278930664, 11.623600006103516, 11.64579963684082, 11.650799751281738, 11.6806001663208, 11.699999809265137, 11.700300216674805, 11.714500427246094, 11.75220012664795, 11.760000228881836, 11.761199951171875, 11.776100158691406, 11.977499961853027, 11.988530158996582, 12.0, 12.026399612426758, 13.0, 13.020000457763672, 13.760600090026855, 13.777999877929688, 13.979999542236328, 14.0, 15.864999771118164, 15.907500267028809, 15.944744110107422, 15.960000038146973, 16.0, 16.020000457763672, 17.230300903320312, 17.314300537109375, 17.32430076599121, 17.443899154663086, 17.562299728393555, 17.641799926757812, 17.664100646972656, 17.98200035095215, 17.98288345336914, 18.0, 19.390300750732422, 19.411300659179688, 19.456899642944336, 19.50659942626953, 19.538999557495117, 19.539499282836914, 19.563199996948242, 19.567399978637695, 19.63920021057129, 19.979999542236328, 20.0, 20.001750946044922, 20.040000915527344, 20.0841007232666, 26.441699981689453, 26.512500762939453, 28.020000457763672, 40.02000045776367, 69.81995391845703, 217.53359985351562, 0, 255, 24401, 32117, 32118, 863314, 2104606, 2236191, 2373188, 2373189, 2576241, 2650447, 4210497, 4210753, 5000266, 5065545, 5329233, 7106160, 7836034, 9605778, 9945660, 10210407, 10330017, 13027530, 14687781, 15562019, 16296474, 16711680, 16777215, 'education', 'registrations', 'associations', 'experience']\n"
     ]
    }
   ],
   "source": [
    "clist = list(resumes_train.columns)\n",
    "clist.remove('body')\n",
    "print(clist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-47b82619a7d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                       ('classifier', LogisticRegression())])\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresumes_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model score: %.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m         \"\"\"\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    316\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_validate_remainder\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    316\u001b[0m         if (hasattr(X, 'columns') and\n\u001b[0;32m    317\u001b[0m                 any(_determine_key_type(cols) == 'str'\n\u001b[1;32m--> 318\u001b[1;33m                     for cols in self._columns)):\n\u001b[0m\u001b[0;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    316\u001b[0m         if (hasattr(X, 'columns') and\n\u001b[0;32m    317\u001b[0m                 any(_determine_key_type(cols) == 'str'\n\u001b[1;32m--> 318\u001b[1;33m                     for cols in self._columns)):\n\u001b[0m\u001b[0;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_determine_key_type\u001b[1;34m(key, accept_slice)\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0munique_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[0mkey_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0m_determine_key_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_key\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<setcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0munique_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[0mkey_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0m_determine_key_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_key\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_determine_key_type\u001b[1;34m(key, accept_slice)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed"
     ]
    }
   ],
   "source": [
    "numeric_features = clist\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['body']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "clf.fit(resumes_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78 entries, 67 to 102\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   body           78 non-null     object\n",
      " 1   fonts          78 non-null     object\n",
      " 2   size           78 non-null     object\n",
      " 3   color          78 non-null     object\n",
      " 4   education      78 non-null     int64 \n",
      " 5   registrations  78 non-null     int64 \n",
      " 6   associations   78 non-null     int64 \n",
      " 7   experience     78 non-null     int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 5.5+ KB\n"
     ]
    }
   ],
   "source": [
    "resumes_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert text into a vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-5a994182bf63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Do not call fit transform twice because it is stored in vectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresumes_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresumes_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         \"\"\"\n\u001b[0;32m   1858\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1859\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1861\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m-> 1220\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \"\"\"\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "\n",
    "# Do not call fit transform twice because it is stored in vectorizer \n",
    "X_train = vectorizer.fit_transform(resumes_train)\n",
    "X_test = vectorizer.transform(resumes_test)\n",
    "y_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=78 does not match number of samples=10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c455777e192a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtext_clf\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    878\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[1;32m--> 265\u001b[1;33m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=78 does not match number of samples=10"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)  \n",
    "text_clf  = classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'NotResume', 'NotResume', 'NotResume',\n",
       "       'NotResume', 'NotResume', 'Resume', 'Resume', 'Resume', 'Resume',\n",
       "       'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume',\n",
       "       'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume',\n",
       "       'Resume', 'Resume', 'Resume', 'Resume', 'Resume', 'Resume'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../downloaded/20.02373 CDOT NPS Western Slope_Ulteig.pdf'\n",
    "fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "count = fileReader.numPages\n",
    "\n",
    "\n",
    "results = text_clf.predict(X_test)\n",
    "resumesTest['results'] = results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "i = 0\n",
    "X_test = []\n",
    "while i < count:\n",
    "    text = fileReader.getPage(i).extractText()\n",
    "    X_test.append(text)\n",
    "    \n",
    "    i = i +1  \n",
    "\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proposal to perform professional engineering services for  gore valley trail design improvements prepared for town of vail angy casamento peangycasamentoulteigcom       february  '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumesTest.loc[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../resumes\\17.00532 0.pdf\n",
      "../resumes\\17.00532 1.pdf\n",
      "../resumes\\17.00532 2.pdf\n",
      "../resumes\\17.00532 3.pdf\n",
      "../resumes\\18.00308 0.pdf\n",
      "../resumes\\18.00308 1.pdf\n",
      "../resumes\\18.00308 2.pdf\n",
      "../resumes\\18.00308 3.pdf\n",
      "../resumes\\19.00064 0.pdf\n",
      "../resumes\\19.00064 1.pdf\n",
      "../resumes\\19.00064 10.pdf\n",
      "../resumes\\19.00064 11.pdf\n",
      "../resumes\\19.00064 2.pdf\n",
      "../resumes\\19.00064 3.pdf\n",
      "../resumes\\19.00064 4.pdf\n",
      "../resumes\\19.00064 5.pdf\n",
      "../resumes\\19.00064 6.pdf\n",
      "../resumes\\19.00064 7.pdf\n",
      "../resumes\\19.00064 8.pdf\n",
      "../resumes\\19.00064 9.pdf\n",
      "../resumes\\20.00432 0.pdf\n",
      "../resumes\\20.00432 1.pdf\n",
      "../resumes\\20.00432 2.pdf\n",
      "../resumes\\20.00432 3.pdf\n",
      "../resumes\\20.00432 4.pdf\n",
      "../resumes\\20.00973 0.pdf\n",
      "../resumes\\20.00973 1.pdf\n",
      "../resumes\\20.00973 10.pdf\n",
      "../resumes\\20.00973 11.pdf\n",
      "../resumes\\20.00973 12.pdf\n",
      "../resumes\\20.00973 2.pdf\n",
      "../resumes\\20.00973 3.pdf\n",
      "../resumes\\20.00973 4.pdf\n",
      "../resumes\\20.00973 5.pdf\n",
      "../resumes\\20.00973 6.pdf\n",
      "../resumes\\20.00973 7.pdf\n",
      "../resumes\\20.00973 8.pdf\n",
      "../resumes\\20.00973 9.pdf\n",
      "../resumes\\20.01139 0.pdf\n",
      "../resumes\\20.01139 1.pdf\n",
      "../resumes\\20.01139 2.pdf\n",
      "../resumes\\20.01139 3.pdf\n",
      "../resumes\\20.01139 4.pdf\n",
      "../resumes\\20.01139 5.pdf\n",
      "../resumes\\20.01139 6.pdf\n",
      "../resumes\\20.01139 7.pdf\n",
      "../resumes\\20.02068 0.pdf\n",
      "../resumes\\20.02068 1.pdf\n",
      "../resumes\\20.02068 2.pdf\n",
      "../resumes\\20.02068 3.pdf\n",
      "../resumes\\20.02068 4.pdf\n",
      "../resumes\\20.02068 5.pdf\n",
      "../resumes\\20.02068 6.pdf\n",
      "../resumes\\20.02068 7.pdf\n",
      "../resumes\\20.02564 0.pdf\n",
      "../resumes\\20.02564 1.pdf\n",
      "../resumes\\20.02564 10.pdf\n",
      "../resumes\\20.02564 11.pdf\n",
      "../resumes\\20.02564 12.pdf\n",
      "../resumes\\20.02564 2.pdf\n",
      "../resumes\\20.02564 3.pdf\n",
      "../resumes\\20.02564 4.pdf\n",
      "../resumes\\20.02564 5.pdf\n",
      "../resumes\\20.02564 6.pdf\n",
      "../resumes\\20.02564 7.pdf\n",
      "../resumes\\20.02564 8.pdf\n",
      "../resumes\\20.02564 9.pdf\n",
      "../resumes\\21.00599 0.pdf\n",
      "../resumes\\21.00599 1.pdf\n",
      "../resumes\\21.00599 10.pdf\n",
      "../resumes\\21.00599 11.pdf\n",
      "../resumes\\21.00599 12.pdf\n",
      "../resumes\\21.00599 13.pdf\n",
      "../resumes\\21.00599 2.pdf\n",
      "../resumes\\21.00599 3.pdf\n",
      "../resumes\\21.00599 4.pdf\n",
      "../resumes\\21.00599 5.pdf\n",
      "../resumes\\21.00599 6.pdf\n",
      "../resumes\\21.00599 7.pdf\n",
      "../resumes\\21.00599 8.pdf\n",
      "../resumes\\21.00599 9.pdf\n",
      "../resumes\\not (1).pdf\n",
      "../resumes\\not (10).pdf\n",
      "../resumes\\not (11).pdf\n",
      "../resumes\\not (12).pdf\n",
      "../resumes\\not (13).pdf\n",
      "../resumes\\not (14).pdf\n",
      "../resumes\\not (15).pdf\n",
      "../resumes\\not (16).pdf\n",
      "../resumes\\not (17).pdf\n",
      "../resumes\\not (18).pdf\n",
      "../resumes\\not (19).pdf\n",
      "../resumes\\not (2).pdf\n",
      "../resumes\\not (20).pdf\n",
      "../resumes\\not (21).pdf\n",
      "../resumes\\not (22).pdf\n",
      "../resumes\\not (23).pdf\n",
      "../resumes\\not (24).pdf\n",
      "../resumes\\not (25).pdf\n",
      "../resumes\\not (26).pdf\n",
      "../resumes\\not (27).pdf\n",
      "../resumes\\not (28).pdf\n",
      "../resumes\\not (29).pdf\n",
      "../resumes\\not (3).pdf\n",
      "../resumes\\not (30).pdf\n",
      "../resumes\\not (31).pdf\n",
      "../resumes\\not (32).pdf\n",
      "../resumes\\not (33).pdf\n",
      "../resumes\\not (34).pdf\n",
      "../resumes\\not (35).pdf\n",
      "../resumes\\not (36).pdf\n",
      "../resumes\\not (4).pdf\n",
      "../resumes\\not (5).pdf\n",
      "../resumes\\not (6).pdf\n",
      "../resumes\\not (7).pdf\n",
      "../resumes\\not (8).pdf\n",
      "../resumes\\not (9).pdf\n"
     ]
    }
   ],
   "source": [
    "# All the pdf files in the folder\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % \"../resumes/\")\n",
    "\n",
    "\n",
    "# Resumes -> convert to a dictionary with an employee name\n",
    "resumes = pd.DataFrame()\n",
    "\n",
    "texts = []\n",
    "# File loop\n",
    "for file in pdf_files:\n",
    "    print(file)\n",
    "    text = \"\"\n",
    "    try:\n",
    "        fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "        count = fileReader.numPages\n",
    "        text = \"\"\n",
    "        i = 0\n",
    "        while i < count:\n",
    "            text += fileReader.getPage(i).extractText()\n",
    "            i = i +1  \n",
    "        # lowercase\n",
    "        text = text.lower()\n",
    "        # remove nubmers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        # remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # remove \\n\n",
    "        text = text.replace('\\n',' ')\n",
    "        # remove nd\n",
    "        text= text.replace('nd',' ')\n",
    "        # remove \\n\n",
    "        text = text.replace('\\n',' ')\n",
    "        # remove \n",
    "        text = text.replace('',' ')\n",
    "        # remove \\n\n",
    "        text = text.replace('\\n',' ')\n",
    "\n",
    "        texts.append(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "resumes['text'] = texts\n",
    "resumes['classification'] = \"Resume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def fonts(doc, granularity=False):\n",
    "    \"\"\"Extracts fonts and their usage in PDF documents.\n",
    "    :param doc: PDF document to iterate through\n",
    "    :type doc: <class 'fitz.fitz.Document'>\n",
    "    :param granularity: also use 'font', 'flags' and 'color' to discriminate text\n",
    "    :type granularity: bool\n",
    "    :rtype: [(font_size, count), (font_size, count}], dict\n",
    "    :return: most used fonts sorted by count, font style information\n",
    "    \"\"\"\n",
    "    styles = {}\n",
    "    font_counts = {}\n",
    "\n",
    "    for page in doc:\n",
    "        blocks = page.getText(\"dict\")[\"blocks\"]\n",
    "        for b in blocks:  # iterate through the text blocks\n",
    "            if b['type'] == 0:  # block contains text\n",
    "                for l in b[\"lines\"]:  # iterate through the text lines\n",
    "                    for s in l[\"spans\"]:  # iterate through the text spans\n",
    "                        if granularity:\n",
    "                            styles[s['font']] =  {'size':s['size'],'color':s['color']}\n",
    "                        else:\n",
    "                            styles[s['font']] =  {'size':s['size'],'color':s['color']}\n",
    "\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "file = '../downloaded/20.02373 CDOT NPS Western Slope_Ulteig.pdf'\n",
    "images = convert_from_path(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the pdf files in the folder\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % \"../resumes/\")\n",
    "\n",
    "# File loop\n",
    "i = 0 \n",
    "for file in pdf_files:\n",
    "    images = convert_from_path(file)\n",
    "    for image in images:\n",
    "        filename = \"resume\" + str(i) + \".jpg\"\n",
    "        image.save(filename, 'JPEG')\n",
    "        i = i +1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
