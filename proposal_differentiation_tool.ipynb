{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposal_Differentiation_Tool - Github\n",
    "\n",
    "Differentiate between Titles, Headers, Body paragraphs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save document (headers & body text) into a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 12,
=======
   "execution_count": 1,
   "id": "6b073b21",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import json\n",
    "from re import findall\n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 25,
=======
   "execution_count": 1,
   "id": "c0dd12a3",
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fitz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fitz' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc = fitz.open(\"./downloaded/pdf.pdf\")\n",
    "\n",
    "# **User input:** Manually identify what page footers & headers are\n",
    "footers_and_headers = [\"Buena Vista\", \"Midland Hills Bridge Trail Development\", \"April 30, 2017\"]\n",
    "\n",
    "def main(doc, footers_and_headers):\n",
    "    # Remove appendix/CVs\n",
    "    print(\"Before appendix/CV removal:\", len(doc), \"pages\")\n",
    "    pages_to_remove = find_extraneous_pages(doc)\n",
    "    remove_extra_pages(doc, pages_to_remove)\n",
    "    print(\"After removal:\", len(doc), \"pages\")\n",
    "    \n",
    "    # Run function to identify what properties are plain text\n",
    "    ct, body_text_props = differentiate_pdf_text(doc)\n",
    "    print()\n",
    "    print_body_text_props(ct, body_text_props)\n",
    "    \n",
    "    # Go back through and save headers & body text to a dict\n",
    "    text_dict = save_to_dict(doc, body_text_props, footers_and_headers)\n",
    "    \n",
    "    # Remove short entries from the dict (results of a table)\n",
    "    text_dict = remove_table_text(text_dict)\n",
    "    \n",
    "    # Print dictionary key:val\n",
    "    for k in text_dict:\n",
    "        print(k, \"\\n'\", text_dict[k], \"'\\n\", sep=\"\")\n",
    "\n",
    "    return\n",
    "\n",
    "main(doc, footers_and_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find body text properties"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 14,
=======
   "execution_count": 2,
   "id": "f202f058",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions for finding the text properties of body text for a pdf document.\n",
    "Save those properties for later use.\n",
    "'''\n",
    "def differentiate_pdf_text(doc):\n",
    "    pages_to_be_deleted = []\n",
    "    ct_by_props = {}\n",
    "    for page_num in range(len(doc) - 1):\n",
    "        # Get page's text (json format)\n",
    "        json_text = doc[page_num].getText(\"json\")\n",
    "\n",
    "        # Convert string/json to usable format (dictionary/lists)\n",
    "        json_text = json.loads(json_text)  \n",
    "        text_blocks = json_text[\"blocks\"]\n",
    "\n",
    "        # Set previous properties to None to prepare for comparisons\n",
    "        prev_props = (None, None)\n",
    "        text_holder = \"\"\n",
    "\n",
    "        # Iterate through all the text entries to count words for each set of properties\n",
    "        for entry in text_blocks: \n",
    "            # Check if this block is an image\n",
    "            try:\n",
    "                img = entry[\"image\"]\n",
    "            except:\n",
    "                img = None\n",
    "                pass\n",
    "\n",
    "            # Check if this block exists, or if the end of the page has been reached\n",
    "            try: \n",
    "                lines = entry[\"lines\"]\n",
    "            except:\n",
    "                lines = None\n",
    "                pass\n",
    "\n",
    "            # Line is not an image and contains text so we continue\n",
    "            if lines != None and img == None:             \n",
    "                for spans in lines:\n",
    "                    # Get the line data\n",
    "                    spans = spans[\"spans\"]                \n",
    "\n",
    "                    for i in range(len(spans)):\n",
    "                        span = spans[i]\n",
    "\n",
    "                        # Identify current line's properties and text\n",
    "                        # put into tuple - (font, size, color)\n",
    "                        props = (span[\"font\"], round(span[\"size\"]))\n",
    "                        text = span[\"text\"]\n",
    "\n",
    "                        ct = count_words(text_holder)\n",
    "\n",
    "                        # Update dictionary\n",
    "                        if props not in ct_by_props:\n",
    "                            ct_by_props[props] = ct\n",
    "                        else:\n",
    "                            ct_by_props[props] = ct_by_props[props] + ct\n",
    "\n",
    "                        # Update text holder & prev properties to new\n",
    "                        text_holder = text\n",
    "                        prev_props = props\n",
    "                        \n",
    "    max_ct, body_text_props = find_body_text(ct_by_props)                    \n",
    "                        \n",
    "    return max_ct, body_text_props"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 15,
=======
   "execution_count": 3,
   "id": "91af2956",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(s):\n",
    "    return len(findall(r'\\w+', s))\n",
    "\n",
    "\n",
    "def find_body_text(ct_by_props):\n",
    "    max_ct = 0\n",
    "    max_ct_props = None\n",
    "    for props in ct_by_props:\n",
    "        props_ct = ct_by_props[props]\n",
    "        if props_ct > max_ct:\n",
    "            max_ct = props_ct\n",
    "            max_ct_props = props\n",
    "    return max_ct, max_ct_props\n",
    "\n",
    "\n",
    "def print_body_text_props(ct, body_text_props):\n",
    "    font = body_text_props[0]\n",
    "    font_size = body_text_props[1]\n",
    "\n",
    "    print(\"Body text properties:\")\n",
    "    print(\"Font:\", font)\n",
    "    print(\"Font Size:\", font_size)\n",
    "    print(\"Number of words:\", ct)\n",
    "    print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extraneous pages (appendix/CVs)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 16,
=======
   "execution_count": 4,
   "id": "0ceb241a",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Finds page numbers that are resumes OR introduction letters'''\n",
    "def find_extraneous_pages(doc):\n",
    "    pages_to_be_deleted = []\n",
    "    for page_num in range(len(doc) - 1):        \n",
    "        # Get page's text (json format)\n",
    "        json_text = doc[page_num].getText(\"json\")\n",
    "\n",
    "        # Convert string/json to usable format (dictionary/lists)\n",
    "        json_text = json.loads(json_text)  \n",
    "        text_blocks = json_text[\"blocks\"]\n",
    "\n",
    "        # Set previous properties to None to prepare for comparisons\n",
    "        prev_props = (None, None, None)\n",
    "        text_holder = \"\"\n",
    "\n",
    "        # Iterate through all the text entries to count words for each set of properties\n",
    "        for entry in text_blocks: \n",
    "            # Check if this block is an image\n",
    "            try:\n",
    "                img = entry[\"image\"]\n",
    "            except:\n",
    "                img = None\n",
    "                pass\n",
    "\n",
    "            # Check if this block exists, or if the end of the page has been reached\n",
    "            try: \n",
    "                lines = entry[\"lines\"]\n",
    "            except:\n",
    "                lines = None\n",
    "                pass\n",
    "\n",
    "            # Line is not an image and contains text so we continue\n",
    "            if lines != None and img == None:             \n",
    "                for spans in lines:\n",
    "                    # Get the line data\n",
    "                    spans = spans[\"spans\"]                \n",
    "\n",
    "                    for i in range(len(spans)):\n",
    "                        span = spans[i]\n",
    "\n",
    "                        # Identify current line's properties and text - (font, size, color)\n",
    "                        props = (span[\"font\"], round(span[\"size\"]), span[\"color\"])\n",
    "                        text = span[\"text\"]\n",
    "\n",
    "                        ct = count_words(text_holder)\n",
    "\n",
    "                        # Check if page is letter\n",
    "                        text_lower = text.lower()\n",
    "                        if (page_num <= 3) and (page_num not in pages_to_be_deleted):\n",
    "                            if (\"re:\" in text_lower):\n",
    "                                print(\"Found letter, \\\"re:\\\", page\", page_num)\n",
    "                                pages_to_be_deleted.append(page_num)\n",
    "                            elif (\"sincerely\" in text_lower):\n",
    "                                print(\"Found letter, \\\"sincerely\\\", page\", page_num)\n",
    "                                pages_to_be_deleted.append(page_num)\n",
    "                        \n",
    "                        # Check resume\n",
    "                        if prev_props == props:\n",
    "                            text_holder += text\n",
    "                        else:\n",
    "                            if is_resume_footer(text_holder, prev_props):\n",
    "                                pages_to_be_deleted.append(page_num) \n",
    "                            text_holder = text\n",
    "                            prev_props = props                   \n",
    "                        \n",
    "    return pages_to_be_deleted"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 17,
=======
   "execution_count": 5,
   "id": "b618543c",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_pages(doc, pages_to_remove = []):\n",
    "    # Remove resumes/letters by page number\n",
    "    for page_num in reversed(pages_to_remove):\n",
    "        doc.deletePage(page_num)\n",
    "\n",
    "    # Find & remove appendix\n",
    "    for page_num in range(len(doc) - 1):\n",
    "        # Check the page word count (Low word count = title page)\n",
    "        plain_text = doc[page_num].getText(\"text\")\n",
    "        page_wordcount = count_words(plain_text)\n",
    "        if page_wordcount < 10:\n",
    "            no_newlines_text = plain_text.replace(\"\\n\", \" \").lower()\n",
    "            # Check if appendix. \n",
    "            if no_newlines_text.startswith(\"table of contents\"):\n",
    "                pass\n",
    "            elif \"appendix\" in no_newlines_text:\n",
    "                # Beginning of the appendix. Remove all subsequent pgs\n",
    "                doc.deletePageRange(page_num, len(doc) - 1)\n",
    "                break\n",
    "            \n",
    "    # Remove cover page\n",
    "    doc.deletePage(0)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 23,
=======
   "execution_count": 6,
   "id": "9f24f234",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_resume_footer(text, props):\n",
    "    ''' \n",
    "    If we can only remove resumes:\n",
    "    1. Check whether a block of text is a resume footer (using text properties & name checking)\n",
    "    2. Probably need to manually remove the resumes from old (pre-2020) pdfs, as they don't match format of new pdfs\n",
    "    '''\n",
    "    resume_footer_props = [('ArialNarrow-Bold', 9, 2576241), ('CIDFont+F3', 9, 2576241)]\n",
    "    '''resume_names = [\"LIZ MANASSEE\", \n",
    "                    \"TOM CONLIN, PE\", \"TOM CONLIN\",\n",
    "                    'JAMES \"KEN\" MCCARRON, PH. D.', 'JAMES \"KEN\" MCCARRON',\n",
    "                    \"ANGY CASAMENTO, PE\", \"ANGY CASAMENTO\", \n",
    "                    \"LUKE ARNOLD\", \"LUKE ARNOLD, PE\", \n",
    "                    \"RICHARD ARCHER, PE\", \"RICHARD ARCHER\", \n",
    "                    \"ROBERT SMITH, PE\", \"ROBERT SMITH\", \n",
    "                    \"CLARK ROBERTS, PE\", \"CLARK ROBERTS\",\n",
    "                    \"ANGY CASAMENTO, PE\", \"ANGY CASAMENTO\", \n",
    "                    \"PAUL MOREAU, PE\", \"PAUL MOREAU\", \n",
    "                    \"ANDI SCHMID, PE\", \"ANDI SCHMID\", \n",
    "                    \"AARON LAUINGER\",]'''\n",
    "    if (props in resume_footer_props):\n",
    "        return True\n",
    "        '''text = text.strip(\"|, \")\n",
    "        if (text in resume_names):\n",
    "            return True'''\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 18,
=======
   "execution_count": 7,
   "id": "cc8201c0",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_table_text(text_dict):\n",
    "    keys = text_dict.keys()\n",
    "    to_delete = []\n",
    "    print(\"deleting:\")\n",
    "    for k in keys:\n",
    "        if len(text_dict[k]) <= 40:\n",
    "            print(text_dict[k])\n",
    "            to_delete.append(k)\n",
    "\n",
    "    for k in to_delete:\n",
    "        del text_dict[k]\n",
    "        \n",
    "    print(\"\\n===================================\\n\")\n",
    "    \n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save document as a dictionary to associate headers w/ body text"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 19,
=======
   "execution_count": 8,
   "id": "c83898e1",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using the previously-found body text properties, save the document into a dictionary.\n",
    "'''\n",
    "def save_to_dict(doc, body_text_props, footers_and_headers=[]):    \n",
    "    text_dict = {}\n",
    "    for page_num in range(len(doc) - 1):\n",
    "        # Get page's text (json format)\n",
    "        json_text = doc[page_num].getText(\"json\")\n",
    "\n",
    "        # Group json entries by those that share the same color&font&size\n",
    "\n",
    "        # Convert string/json to usable format (dictionary/lists)\n",
    "        json_text = json.loads(json_text)  \n",
    "        text_blocks = json_text[\"blocks\"]\n",
    "\n",
    "        # Set previous properties to None to prepare for comparisons\n",
    "        prev_props = (None, None)\n",
    "        prev_type = None\n",
    "        text_holder = \"\"\n",
    "\n",
    "        # Iterate through all the text entries\n",
    "        for entry in text_blocks:\n",
    "            # Check if this block is an image\n",
    "            try:\n",
    "                img = entry[\"image\"]\n",
    "            except:\n",
    "                img = None\n",
    "                pass\n",
    "\n",
    "            # Check if this block exists, or if the end of the page has been reached\n",
    "            try: \n",
    "                lines = entry[\"lines\"]\n",
    "            except:\n",
    "                lines = None\n",
    "                pass\n",
    "\n",
    "            # Line is not an image and contains text so we continue\n",
    "            if lines != None and img == None:             \n",
    "                for spans in lines:\n",
    "                    # Get the line data\n",
    "                    spans = spans[\"spans\"]                \n",
    "\n",
    "                    for i in range(len(spans)):\n",
    "                        span = spans[i]\n",
    "\n",
    "                        # Identify current line's properties and text\n",
    "                        props = (span[\"font\"], round(span[\"size\"]))\n",
    "                        color = span[\"color\"]\n",
    "                        text = span[\"text\"].strip()\n",
    "                        \n",
    "                        if (len(text) > 2) and (text not in footers_and_headers):\n",
    "                        # if text != \"\":\n",
    "                            # Check if current line is body text                        \n",
    "                            if props == body_text_props and is_color_grayscale(color):\n",
    "                                prev_type = \"body\"\n",
    "                                prev_props = props\n",
    "                                try:\n",
    "                                    text_dict[header] += \" \" + text\n",
    "                                except KeyError:\n",
    "                                    text_dict[header] = text\n",
    "                            elif ((props[0].rstrip(\"-Bold\")) == body_text_props[0]) \\\n",
    "                            and (props[1] == body_text_props[1]) and is_color_grayscale(color):\n",
    "                                prev_type = \"body\"\n",
    "                                prev_props = props\n",
    "                                try:\n",
    "                                    text_dict[header] += \" \" + text\n",
    "                                except KeyError:\n",
    "                                    text_dict[header] = text\n",
    "                            else: \n",
    "                                # Not body text.\n",
    "                                if prev_type == \"header\" and prev_props == props:\n",
    "                                    header += \" \" + text\n",
    "                                else:\n",
    "                                    header = text\n",
    "                                prev_type = \"header\"\n",
    "                                prev_props = props\n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 20,
=======
   "execution_count": 9,
   "id": "66781585",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_color_grayscale(srgb_color):\n",
    "    # Is the color approximately grayscale?\n",
    "    rgb = get_rgb_color(srgb_color)\n",
    "    if max(rgb) - min(rgb) <= 40:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "    \n",
    "def get_rgb_color(srgb_color_code):\n",
    "    cc = fitz.sRGB_to_rgb(srgb_color_code)\n",
    "    return cc\n",
    "    \n",
    "is_color_grayscale(2373188)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes section (Misc. code used for debugging)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 21,
=======
   "execution_count": 54,
   "id": "a8f0d725",
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewsGothicStd 10 (255, 255, 255) | \"proposal to perform services for \"\n",
      "NewsGothicStd 14 (255, 255, 255) | \"Midland Hills Bridge Trail Development\"\n",
      "NewsGothicStd 10 (255, 255, 255) | \"prepared for the \"\n",
      "NewsGothicStd 14 (255, 255, 255) | \"Town of Buena Vista\"\n",
      "NewsGothicStd-Bold 12 (255, 255, 255) | \"Angy Casamento, PE\"\n",
      "NewsGothicStd 10 (255, 255, 255) | \"angy.casamento@ulteig.com | 720.873.5892 \"\n",
      "NewsGothicStd 10 (255, 255, 255) | \"17.00532 | April 30, 2017\"\n"
     ]
    }
   ],
   "source": [
    "doc = fitz.open(\"./downloaded/17.00532 Buena Vista CO_Midland Hills Bridge Trail Development_Apr17_P17.00532_FINAL_.pdf\")\n",
    "page_num = 0\n",
    "\n",
    "def get_props_text(doc, page_num):\n",
    "    # Get page's text (json format)\n",
    "    json_text = doc[page_num].getText(\"json\")\n",
    "\n",
    "    # Convert string/json to usable format (dictionary/lists)\n",
    "    json_text = json.loads(json_text)  \n",
    "    text_blocks = json_text[\"blocks\"]\n",
    "\n",
    "    # Iterate through all the text entries to count words for each set of properties\n",
    "    for entry in text_blocks: \n",
    "        # Check if this block is an image\n",
    "        try:\n",
    "            img = entry[\"image\"]\n",
    "        except:\n",
    "            img = None\n",
    "            pass\n",
    "\n",
    "        # Check if this block exists, or if the end of the page has been reached\n",
    "        try: \n",
    "            lines = entry[\"lines\"]\n",
    "        except:\n",
    "            lines = None\n",
    "            pass\n",
    "\n",
    "        # Line is not an image and contains text so we continue\n",
    "        if lines != None and img == None:             \n",
    "            for spans in lines:\n",
    "                # Get the line data\n",
    "                spans = spans[\"spans\"]                \n",
    "\n",
    "                for i in range(len(spans)):\n",
    "                    span = spans[i]\n",
    "                    # Identify current line's properties and text\n",
    "                    # put into tuple - (font, size, color)\n",
    "                    props = (span[\"font\"], round(span[\"size\"]), span[\"color\"])\n",
    "                    text = span[\"text\"]\n",
    "                    text = text.strip(\"|\")\n",
    "                    print(span[\"font\"], round(span[\"size\"]), get_rgb_color(span[\"color\"]), \"|\", end=\" \")\n",
    "                    print(\"\\\"\", text, \"\\\"\", sep=\"\")\n",
    "    return\n",
    "\n",
    "get_props_text(doc, page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== filename would go here (f) =====\n",
      "Before appendix/CV removal: 29 pages\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'is_resume_footer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ec833d3255b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=====\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"filename would go here (f)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"=====\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Before appendix/CV removal:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pages\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mpages_to_remove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_extraneous_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mremove_extra_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages_to_remove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"After removal:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pages\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-9e51d412dff3>\u001b[0m in \u001b[0;36mfind_extraneous_pages\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     59\u001b[0m                             \u001b[0mtext_holder\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                             \u001b[1;32mif\u001b[0m \u001b[0mis_resume_footer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_holder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_props\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m                                 \u001b[0mpages_to_be_deleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                             \u001b[0mtext_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'is_resume_footer' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Iterate over every proposal. \n",
    "Check what page numbers are being identified as resumes & removed.\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "directory = './downloaded/'\n",
    " \n",
    "# iterate over files in that directory\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    doc = fitz.open(f)\n",
    "\n",
    "    # Remove appendix/CVs\n",
    "    print(\"=====\", \"filename would go here (f)\", \"=====\")\n",
    "    print(\"Before appendix/CV removal:\", len(doc), \"pages\")\n",
    "    pages_to_remove = find_extraneous_pages(doc)\n",
    "    remove_extra_pages(doc, pages_to_remove)\n",
    "    print(\"After removal:\", len(doc), \"pages\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cannot open ./downloaded/.pdf: No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot open ./downloaded/.pdf: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-3c53b3f30814>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check what style is like for json entries/spans/span/text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./downloaded/.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpage_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_first_entry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\fitz\\fitz.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[0;32m   3605\u001b[0m         _fitz.Document_swiginit(\n\u001b[0;32m   3606\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3607\u001b[1;33m             _fitz.new_Document(\n\u001b[0m\u001b[0;32m   3608\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiletype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3609\u001b[0m             ),\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot open ./downloaded/.pdf: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Check what style is like for json entries/spans/span/text\n",
    "doc = fitz.open(\"./downloaded/.pdf\")\n",
    "page_num = 13\n",
    "\n",
    "def print_first_entry(doc, page_num):\n",
    "    # Get page's text (json format)\n",
    "    json_text = doc[page_num].getText(\"json\")\n",
    "\n",
    "    # Convert string/json to usable format (dictionary/lists)\n",
    "    json_text = json.loads(json_text)  \n",
    "    text_blocks = json_text[\"blocks\"]\n",
    "    \n",
    "    # Iterate through all the text entries\n",
    "    for entry in text_blocks:\n",
    "        \n",
    "        lines = entry[\"lines\"]\n",
    "        print(\"LINES:\\n\", lines, \"\\n\")\n",
    "\n",
    "        if lines != None:\n",
    "            for spans in lines:       \n",
    "                # Get the line data\n",
    "                spans = spans[\"spans\"]\n",
    "                \n",
    "                print(\"SPANS:\\n\", spans, \"\\n\")\n",
    "\n",
    "                for i in range(len(spans)):\n",
    "                    span = spans[i]\n",
    "                    \n",
    "                    print(\"SPAN:\\n\", span, \"\\n\")\n",
    "                    \n",
    "                    # Identify current line's properties and text\n",
    "                    text = span[\"text\"]\n",
    "                    print(\"TEXT:\\n\", text, \"\\n\")\n",
    "        break\n",
    "    return\n",
    "\n",
    "print_first_entry(doc,page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cannot open ./downloaded/pdf.pdf: No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot open ./downloaded/pdf.pdf: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-2541fe9df503>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./downloaded/pdf.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpage_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_json_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Get page's text (json format)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\fitz\\fitz.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[0;32m   3605\u001b[0m         _fitz.Document_swiginit(\n\u001b[0;32m   3606\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3607\u001b[1;33m             _fitz.new_Document(\n\u001b[0m\u001b[0;32m   3608\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiletype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3609\u001b[0m             ),\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot open ./downloaded/pdf.pdf: No such file or directory"
     ]
    }
   ],
   "source": [
    "doc = fitz.open(\"./downloaded/pdf.pdf\")\n",
    "page_num = 30\n",
    "\n",
    "def get_json_text(doc, page_num):\n",
    "    # Get page's text (json format)\n",
    "    json_text = doc[page_num].getText(\"json\")\n",
    "\n",
    "    # Group json entries by those that share the same color&font&size\n",
    "\n",
    "    # Convert string/json to usable format (dictionary/lists)\n",
    "    json_text = json.loads(json_text)  \n",
    "    text_blocks = json_text[\"blocks\"]\n",
    "    return print(text_blocks)\n",
    "\n",
    "get_json_text(doc, page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cannot open ./downloaded/PDF.pdf: No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot open ./downloaded/PDF.pdf: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-062e11b72b73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./downloaded/PDF.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpage_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Get page's text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\fitz\\fitz.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[0;32m   3605\u001b[0m         _fitz.Document_swiginit(\n\u001b[0;32m   3606\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3607\u001b[1;33m             _fitz.new_Document(\n\u001b[0m\u001b[0;32m   3608\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiletype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3609\u001b[0m             ),\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot open ./downloaded/PDF.pdf: No such file or directory"
     ]
    }
   ],
   "source": [
    "doc = fitz.open(\"./downloaded/PDF.pdf\")\n",
    "page_num = 4\n",
    "\n",
    "def get_plain_text(doc, page_num):\n",
    "    # Get page's text\n",
    "    plain_text = doc[page_num].getText(\"text\")\n",
    "    no_newlines_text = plain_text.replace(\"\\n\", \" \").lower()\n",
    "    print(no_newlines_text)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cannot open ./downloaded/.pdf: No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot open ./downloaded/.pdf: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-27d15942e5a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./downloaded/.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpage_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhandle_title_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplain_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpage_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\fitz\\fitz.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[0;32m   3605\u001b[0m         _fitz.Document_swiginit(\n\u001b[0;32m   3606\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3607\u001b[1;33m             _fitz.new_Document(\n\u001b[0m\u001b[0;32m   3608\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiletype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3609\u001b[0m             ),\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot open ./downloaded/.pdf: No such file or directory"
     ]
    }
   ],
   "source": [
    "doc = fitz.open(\"./downloaded/.pdf\")\n",
    "page_num = 4\n",
    "\n",
    "def handle_title_page(doc, page_num):\n",
    "    plain_text = doc[page_num].getText(\"text\")\n",
    "    no_newlines_text = plain_text.replace(\"\\n\", \" \").lower()\n",
    "    print(no_newlines_text)\n",
    "    \n",
    "    # Check if ToC, or appendix.\n",
    "    if no_newlines_text.startswith(\"table of contents\"):\n",
    "        print(\"toc\")\n",
    "    elif no_newlines_text.startswith(\"appendix\"):\n",
    "        print(\"appendix\")\n",
    "    else:\n",
    "        print(\"neither\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
